{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Attribution with CRP\n",
    "\n",
    "This notebook demonstrates how to use Concept Relevance Propagation (CRP) for time series classification models.\n",
    "We'll analyze a 1D CNN trained on vibration data to understand which temporal patterns and channels (X, Y, Z) contribute to classification decisions.\n",
    "\n",
    "## Overview\n",
    "- **Data**: 3-channel vibration time series (shape: [batch, 3, 2000])\n",
    "- **Model**: 1D CNN for binary classification (good vs bad)\n",
    "- **Goal**: Understand which time segments and channels are most relevant for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the CRP modules to path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import CRP components\n",
    "from crp.attribution import CondAttribution\n",
    "from crp.helper import get_layer_names\n",
    "from crp.graph import trace_model_graph\n",
    "\n",
    "# Import our adapted components\n",
    "from time_series_concepts import TimeSeriesConcept\n",
    "from time_series_visualization import (\n",
    "    plot_time_series_with_relevance, \n",
    "    plot_channel_importance,\n",
    "    visualize_temporal_concepts\n",
    ")\n",
    "\n",
    "# Import your model and dataset\n",
    "from cnn1d_model import CNN1D_Wide, VibrationDataset\n",
    "\n",
    "# Zennit composites for different LRP rules\n",
    "from zennit.composites import EpsilonGammaBox, EpsilonPlus, EpsilonAlpha2Beta1\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load trained model\n",
    "model = CNN1D_Wide()\n",
    "model.load_state_dict(torch.load('../cnn1d_model.ckpt', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = \"../data/final/new_selection/normalized_windowed_downsampled_data\"\n",
    "dataset = VibrationDataset(data_dir)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Classes: Good ({sum(dataset.labels == 0)}), Bad ({sum(dataset.labels == 1)})\")\n",
    "\n",
    "# Get a sample for analysis\n",
    "sample_data, sample_label = dataset[100]  # Choose an interesting sample\n",
    "sample_data = sample_data.unsqueeze(0).to(device)  # Add batch dimension\n",
    "sample_data.requires_grad = True\n",
    "\n",
    "print(f\"Sample shape: {sample_data.shape}\")\n",
    "print(f\"Sample label: {'Good' if sample_label == 0 else 'Bad'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Analysis Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get layer names from the model\n",
    "conv_layer_names = get_layer_names(model, [nn.Conv1d])\n",
    "linear_layer_names = get_layer_names(model, [nn.Linear])\n",
    "all_layer_names = conv_layer_names + linear_layer_names\n",
    "\n",
    "print(\"Convolutional layers:\")\n",
    "for name in conv_layer_names:\n",
    "    print(f\"  - {name}\")\n",
    "    \n",
    "print(\"\\nLinear layers:\")\n",
    "for name in linear_layer_names:\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Create layer mapping with TimeSeriesConcept\n",
    "layer_map = {name: TimeSeriesConcept() for name in all_layer_names}\n",
    "\n",
    "print(f\"\\nCreated concept mapping for {len(layer_map)} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model graph for understanding layer connections\n",
    "graph = trace_model_graph(model, sample_data, all_layer_names)\n",
    "\n",
    "print(\"Model graph created successfully!\")\n",
    "print(\"\\nLayer connections:\")\n",
    "for layer_name in conv_layer_names[:3]:  # Show first 3 layers\n",
    "    input_layers = graph.find_input_layers(layer_name)\n",
    "    print(f\"{layer_name} <- {input_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribution object\n",
    "attribution = CondAttribution(model, device)\n",
    "\n",
    "print(\"Attribution object created!\")\n",
    "print(f\"Model device: {attribution.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Attribution Analysis\n",
    "\n",
    "Let's start with a simple attribution to understand which input time points are most relevant for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model prediction first\n",
    "with torch.no_grad():\n",
    "    prediction = model(sample_data)\n",
    "    predicted_class = torch.argmax(prediction, dim=1)\n",
    "    confidence = torch.softmax(prediction, dim=1)\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Predicted class: {'Good' if predicted_class == 0 else 'Bad'}\")\n",
    "print(f\"Confidence: Good={confidence[0,0]:.3f}, Bad={confidence[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different LRP rules to compare\n",
    "composites = {\n",
    "    'Epsilon-Gamma': EpsilonGammaBox(low=-1, high=1, gamma=0.25),\n",
    "    'Epsilon-Plus': EpsilonPlus(),\n",
    "    'Alpha-Beta': EpsilonAlpha2Beta1()\n",
    "}\n",
    "\n",
    "# Simple attribution: analyze prediction with respect to predicted class\n",
    "conditions = [{'y': [predicted_class.item()]}]  # 'y' refers to model output\n",
    "\n",
    "results = {}\n",
    "for rule_name, composite in composites.items():\n",
    "    print(f\"Computing attribution with {rule_name}...\")\n",
    "    result = attribution(sample_data, conditions, composite)\n",
    "    results[rule_name] = result\n",
    "    print(f\"  Heatmap shape: {result.heatmap.shape}\")\n",
    "    print(f\"  Heatmap range: [{result.heatmap.min():.4f}, {result.heatmap.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize basic attribution results\n",
    "fig, axes = plt.subplots(len(composites) + 1, 1, figsize=(15, 4*(len(composites) + 1)))\n",
    "\n",
    "# Plot original time series\n",
    "channel_names = ['X', 'Y', 'Z']\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "for ch in range(3):\n",
    "    axes[0].plot(sample_data[0, ch, :].cpu().detach().numpy(), \n",
    "                 color=colors[ch], alpha=0.7, label=f'Channel {channel_names[ch]}')\n",
    "axes[0].set_title(f'Original Time Series - Label: {\\'Good\\' if sample_label == 0 else \\'Bad\\'}')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot attribution heatmaps\n",
    "for i, (rule_name, result) in enumerate(results.items()):\n",
    "    heatmap = result.heatmap[0].cpu().detach().numpy()  # Remove batch dimension\n",
    "    \n",
    "    axes[i+1].fill_between(range(len(heatmap)), 0, heatmap, \n",
    "                          alpha=0.7, color='red' if heatmap.sum() > 0 else 'blue')\n",
    "    axes[i+1].set_title(f'Attribution Heatmap - {rule_name}')\n",
    "    axes[i+1].set_ylabel('Relevance')\n",
    "    axes[i+1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time Steps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Layer-wise Attribution Analysis\n",
    "\n",
    "Now let's analyze specific layers to understand what concepts they learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze first convolutional layer concepts\n",
    "layer_to_analyze = conv_layer_names[0]  # First conv layer\n",
    "print(f\"Analyzing layer: {layer_to_analyze}\")\n",
    "\n",
    "# Get layer output shape for understanding\n",
    "with torch.no_grad():\n",
    "    # Forward pass to get intermediate activations\n",
    "    handles = []\n",
    "    layer_outputs = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            layer_outputs[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hook\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_to_analyze:\n",
    "            handle = module.register_forward_hook(get_activation(name))\n",
    "            handles.append(handle)\n",
    "    \n",
    "    _ = model(sample_data)\n",
    "    \n",
    "    # Remove hooks\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "\n",
    "layer_output = layer_outputs[layer_to_analyze]\n",
    "print(f\"Layer output shape: {layer_output.shape}\")\n",
    "print(f\"Number of channels/concepts: {layer_output.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific channels/concepts in the layer\n",
    "num_channels = layer_output.shape[1]\n",
    "channels_to_analyze = list(range(min(6, num_channels)))  # Analyze first 6 channels\n",
    "\n",
    "print(f\"Analyzing channels: {channels_to_analyze}\")\n",
    "\n",
    "# Create conditions for each channel\n",
    "channel_conditions = [{layer_to_analyze: [ch]} for ch in channels_to_analyze]\n",
    "\n",
    "# Use Epsilon-Gamma rule for this analysis\n",
    "composite = EpsilonGammaBox(low=-1, high=1, gamma=0.25)\n",
    "\n",
    "# Compute attribution for each channel\n",
    "channel_results = []\n",
    "for i, condition in enumerate(channel_conditions):\n",
    "    print(f\"Computing attribution for channel {channels_to_analyze[i]}...\")\n",
    "    result = attribution(sample_data, [condition], composite, \n",
    "                        record_layer=[layer_to_analyze])\n",
    "    channel_results.append(result)\n",
    "    \n",
    "print(\"Channel-wise attribution complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize channel-wise attributions\n",
    "fig, axes = plt.subplots(len(channels_to_analyze) + 1, 1, \n",
    "                        figsize=(15, 3*(len(channels_to_analyze) + 1)))\n",
    "\n",
    "# Plot original signal\n",
    "for ch in range(3):\n",
    "    axes[0].plot(sample_data[0, ch, :].cpu().detach().numpy(), \n",
    "                 color=colors[ch], alpha=0.7, label=f'Channel {channel_names[ch]}')\n",
    "axes[0].set_title('Original Time Series')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot each channel's attribution\n",
    "for i, (ch_idx, result) in enumerate(zip(channels_to_analyze, channel_results)):\n",
    "    heatmap = result.heatmap[0].cpu().detach().numpy()\n",
    "    \n",
    "    axes[i+1].fill_between(range(len(heatmap)), 0, heatmap, alpha=0.7, \n",
    "                          color=f'C{i}', label=f'Channel {ch_idx}')\n",
    "    axes[i+1].set_title(f'Attribution for {layer_to_analyze} - Channel {ch_idx}')\n",
    "    axes[i+1].set_ylabel('Relevance')\n",
    "    axes[i+1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time Steps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Concept Activation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what activates each concept/channel\n",
    "# Get activations and relevances from the recorded layer\n",
    "\n",
    "if len(channel_results) > 0 and layer_to_analyze in channel_results[0].activations:\n",
    "    # Get activations for the analyzed layer\n",
    "    activations = channel_results[0].activations[layer_to_analyze]\n",
    "    print(f\"Activations shape: {activations.shape}\")\n",
    "    \n",
    "    # Visualize activation patterns\n",
    "    fig = visualize_temporal_concepts(activations, layer_to_analyze, top_k=6)\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze channel importance\n",
    "    concept = TimeSeriesConcept()\n",
    "    \n",
    "    for i, result in enumerate(channel_results[:3]):  # First 3 channels\n",
    "        if layer_to_analyze in result.relevances:\n",
    "            relevance = result.relevances[layer_to_analyze]\n",
    "            channel_attribution = concept.attribute(relevance)\n",
    "            \n",
    "            print(f\"Channel {channels_to_analyze[i]} attribution shape: {channel_attribution.shape}\")\n",
    "            print(f\"Channel {channels_to_analyze[i]} importance: {channel_attribution[0].abs().sum().item():.4f}\")\n",
    "else:\n",
    "    print(\"No activations recorded for the specified layer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis: Good vs Bad Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one good and one bad sample for comparison\n",
    "good_indices = np.where(dataset.labels == 0)[0]\n",
    "bad_indices = np.where(dataset.labels == 1)[0]\n",
    "\n",
    "good_idx = good_indices[50]  # Choose a good sample\n",
    "bad_idx = bad_indices[50]   # Choose a bad sample\n",
    "\n",
    "good_data, good_label = dataset[good_idx]\n",
    "bad_data, bad_label = dataset[bad_idx]\n",
    "\n",
    "good_data = good_data.unsqueeze(0).to(device).requires_grad_(True)\n",
    "bad_data = bad_data.unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "print(f\"Good sample index: {good_idx}, Bad sample index: {bad_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions for both samples\n",
    "with torch.no_grad():\n",
    "    good_pred = model(good_data)\n",
    "    bad_pred = model(bad_data)\n",
    "    \n",
    "    good_class = torch.argmax(good_pred, dim=1)\n",
    "    bad_class = torch.argmax(bad_pred, dim=1)\n",
    "    \n",
    "    good_conf = torch.softmax(good_pred, dim=1)\n",
    "    bad_conf = torch.softmax(bad_pred, dim=1)\n",
    "\n",
    "print(f\"Good sample - Predicted: {'Good' if good_class == 0 else 'Bad'}, Confidence: {good_conf[0, good_class]:.3f}\")\n",
    "print(f\"Bad sample - Predicted: {'Good' if bad_class == 0 else 'Bad'}, Confidence: {bad_conf[0, bad_class]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute attributions for both samples\n",
    "composite = EpsilonGammaBox(low=-1, high=1, gamma=0.25)\n",
    "\n",
    "good_conditions = [{'y': [good_class.item()]}]\n",
    "bad_conditions = [{'y': [bad_class.item()]}]\n",
    "\n",
    "good_result = attribution(good_data, good_conditions, composite)\n",
    "bad_result = attribution(bad_data, bad_conditions, composite)\n",
    "\n",
    "print(\"Comparative attribution computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 16))\n",
    "\n",
    "# Good sample\n",
    "for ch in range(3):\n",
    "    axes[0].plot(good_data[0, ch, :].cpu().detach().numpy(), \n",
    "                 color=colors[ch], alpha=0.7, label=f'Channel {channel_names[ch]}')\n",
    "axes[0].set_title(f'Good Sample (Confidence: {good_conf[0, good_class]:.3f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Good sample attribution\n",
    "good_heatmap = good_result.heatmap[0].cpu().detach().numpy()\n",
    "axes[1].fill_between(range(len(good_heatmap)), 0, good_heatmap, \n",
    "                    alpha=0.7, color='green', label='Good Attribution')\n",
    "axes[1].set_title('Good Sample Attribution')\n",
    "axes[1].set_ylabel('Relevance')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bad sample\n",
    "for ch in range(3):\n",
    "    axes[2].plot(bad_data[0, ch, :].cpu().detach().numpy(), \n",
    "                 color=colors[ch], alpha=0.7, label=f'Channel {channel_names[ch]}')\n",
    "axes[2].set_title(f'Bad Sample (Confidence: {bad_conf[0, bad_class]:.3f})')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Bad sample attribution\n",
    "bad_heatmap = bad_result.heatmap[0].cpu().detach().numpy()\n",
    "axes[3].fill_between(range(len(bad_heatmap)), 0, bad_heatmap, \n",
    "                    alpha=0.7, color='red', label='Bad Attribution')\n",
    "axes[3].set_title('Bad Sample Attribution')\n",
    "axes[3].set_ylabel('Relevance')\n",
    "axes[3].set_xlabel('Time Steps')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "def analyze_temporal_importance(heatmap, window_size=100):\n",
    "    \"\"\"Analyze which time windows are most important\"\"\"\n",
    "    n_windows = len(heatmap) // window_size\n",
    "    window_importance = []\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        start_idx = i * window_size\n",
    "        end_idx = (i + 1) * window_size\n",
    "        window_rel = heatmap[start_idx:end_idx].sum()\n",
    "        window_importance.append(window_rel)\n",
    "    \n",
    "    return np.array(window_importance)\n",
    "\n",
    "# Analyze good vs bad temporal patterns\n",
    "good_temporal = analyze_temporal_importance(good_heatmap)\n",
    "bad_temporal = analyze_temporal_importance(bad_heatmap)\n",
    "\n",
    "print(\"Temporal Analysis (per 100-step windows):\")\n",
    "print(f\"Good sample - Most important window: {np.argmax(np.abs(good_temporal))} (relevance: {good_temporal[np.argmax(np.abs(good_temporal))]:.4f})\")\n",
    "print(f\"Bad sample - Most important window: {np.argmax(np.abs(bad_temporal))} (relevance: {bad_temporal[np.argmax(np.abs(bad_temporal))]:.4f})\")\n",
    "\n",
    "# Plot temporal window analysis\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "window_centers = np.arange(len(good_temporal)) * 100 + 50\n",
    "ax1.bar(window_centers, good_temporal, width=80, alpha=0.7, color='green', label='Good Sample')\n",
    "ax1.set_title('Temporal Window Importance - Good Sample')\n",
    "ax1.set_ylabel('Relevance')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.bar(window_centers, bad_temporal, width=80, alpha=0.7, color='red', label='Bad Sample')\n",
    "ax2.set_title('Temporal Window Importance - Bad Sample')\n",
    "ax2.set_xlabel('Time Steps (Window Center)')\n",
    "ax2.set_ylabel('Relevance')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "Based on the attribution analysis:\n",
    "\n",
    "1. **Temporal Patterns**: The model focuses on specific time windows for classification\n",
    "2. **Channel Importance**: Different vibration channels (X, Y, Z) may have varying importance\n",
    "3. **Layer Concepts**: Early layers capture low-level temporal patterns, deeper layers capture more complex patterns\n",
    "4. **Decision Differences**: Good and bad samples show different attribution patterns\n",
    "\n",
    "This analysis helps understand:\n",
    "- Which time segments are critical for fault detection\n",
    "- How the model processes multi-channel vibration data\n",
    "- What temporal features distinguish good from bad samples\n",
    "- Whether the model's decisions align with domain knowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}